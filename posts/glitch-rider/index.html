<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Glitch Rider | This is slerpy</title><meta name=keywords content="demoscene,4k,intro"><meta name=description content="a 4k PC intro released at Evoke 2019
[pouët]
This entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb. It is the spiritual successor to Kill the Encoder, which was my last 4k intro at the time.
Data Moshing Many video codecs use inter-frame compression. The idea is that a frame in a video typically looks similar to the frames immediately before and after it, so most of the time, you can get away with storing only what changed between frames rather than storing all the frames individually."><meta name=author content><link rel=canonical href=https://slerpy.xyz/posts/glitch-rider/><link crossorigin=anonymous href=/assets/css/stylesheet.7cea68b77c83e5da57c9a11c56919d4de2e6847751854f818c1d6aeb21f21f85.css integrity="sha256-fOpot3yD5dpXyaEcVpGdTeLmhHdRhU+BjB1q6yHyH4U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://slerpy.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://slerpy.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://slerpy.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://slerpy.xyz/apple-touch-icon.png><link rel=mask-icon href=https://slerpy.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Glitch Rider"><meta property="og:description" content="a 4k PC intro released at Evoke 2019
[pouët]
This entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb. It is the spiritual successor to Kill the Encoder, which was my last 4k intro at the time.
Data Moshing Many video codecs use inter-frame compression. The idea is that a frame in a video typically looks similar to the frames immediately before and after it, so most of the time, you can get away with storing only what changed between frames rather than storing all the frames individually."><meta property="og:type" content="article"><meta property="og:url" content="https://slerpy.xyz/posts/glitch-rider/"><meta property="og:image" content="https://slerpy.xyz/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-08-19T00:00:00+00:00"><meta property="article:modified_time" content="2019-08-19T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://slerpy.xyz/papermod-cover.png"><meta name=twitter:title content="Glitch Rider"><meta name=twitter:description content="a 4k PC intro released at Evoke 2019
[pouët]
This entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb. It is the spiritual successor to Kill the Encoder, which was my last 4k intro at the time.
Data Moshing Many video codecs use inter-frame compression. The idea is that a frame in a video typically looks similar to the frames immediately before and after it, so most of the time, you can get away with storing only what changed between frames rather than storing all the frames individually."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://slerpy.xyz/posts/"},{"@type":"ListItem","position":2,"name":"Glitch Rider","item":"https://slerpy.xyz/posts/glitch-rider/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Glitch Rider","name":"Glitch Rider","description":"a 4k PC intro released at Evoke 2019\n[pouët]\nThis entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb. It is the spiritual successor to Kill the Encoder, which was my last 4k intro at the time.\nData Moshing Many video codecs use inter-frame compression. The idea is that a frame in a video typically looks similar to the frames immediately before and after it, so most of the time, you can get away with storing only what changed between frames rather than storing all the frames individually.","keywords":["demoscene","4k","intro"],"articleBody":"a 4k PC intro released at Evoke 2019\n[pouët]\nThis entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb. It is the spiritual successor to Kill the Encoder, which was my last 4k intro at the time.\nData Moshing Many video codecs use inter-frame compression. The idea is that a frame in a video typically looks similar to the frames immediately before and after it, so most of the time, you can get away with storing only what changed between frames rather than storing all the frames individually. Roughly speaking, videos compressed this way are encoded as a sequence of I-frames and P-frames, where An I-frame (intra-frame) specifies what an image looks like at the current point in time, and a P-frame (predicted frame) only encodes changes between frames, i.e. what transformations need to be applied to a different frame to obtain the current frame.\nIf an I-frame is corrupted or removed, the subsequent P-frames apply their transformations to the wrong base image. If this happens while the video cuts from one shot to another, you get the changes and camera movement from one shot but applied to another. This is what we call data moshing. There are plenty of tools that allow you to strategically remove I-frames from video files to create this effect yourself, but of course, I couldn't use those in a 4k intro.\nHow to fake it The intro takes a very different approach. First, we do the usual camera ray intersection to find the surface point p. Next, we check if p was on-screen on the previous frame, first by checking if the point was occluded using another ray intersection, then by computing the pixel coordinate where p should be visible and checking if it's within the bounds of the frame. If we find p in the previous frame, we simply display its color, otherwise, we compute it from scratch.\nThis gives us a method to have textures \"stick\" to the geometry, similar to what TAA does. Note that we only ever think about where the camera was in the last frame, this method completely falls apart when the geometry moves, which is why the scene is completely static in the intro. In the shader, moving all the camera setup/movement into a separate camera function that takes the current time as a parameter makes this fairly easy to implement.\nIn its current state, if the camera jumps from one scene to another, it detects that none of the points it sees were on-screen in the previous frame and discards all of them. To get this data-moshing effect, we want to prevent it from detecting scene transitions like that. So, to \"remove the I-frame\", we base all our jumps between scenes of the time of the current frame inside the camera function. This way, we lie to the algorithm about where the camera was last frame, and that last frame sticks to the new geometry after the cut.\nIf you want to play around with that effect, I made Data Moshing Effect, a minimal Shadertoy that implements this algorithm. Or rather, the intro is a fork of this Shadertoy.\nSome remarks You might notice that the Shadertoy uses one more buffer than necessary. This is because every time the above algorithm is applied, it introduces a small amount of error when fetching the texture. So if you always fetch the previous frame, you get an extremely unstable feedback loop where the image quickly starts to blur or deform. To break this feedback loop, the shader only updates the \"previous frame\" texture every 8 frames.\nSince posting the Shadertoy, I have received multiple requests to rewrite the algorithm to work on arbitrary videos. This is not feasible, as the algorithm relies on exact knowledge of the geometry in the scene and precise 3D coordinates for every pixel on the screen. If you want to data-mosh videos, messing with the video file directly is much easier.\nConclusion This entry won first place in the 4k intro compo, though arguably Eisenerz by LJ \u0026 Virgill should have won 1. When I first saw LJ's intro, I had doubts whether I should even submit mine. I'm glad the other Alcatraz members talked me into it.\nAlso, thank you to xTr1m and Gopher for helping me debug this mess.\nAs I found out later, the live voting system stopped accepting votes almost immediately after Eisenerz, the last intro in the compo, was shown, meaning many votes for this intro were simply not counted. There is no doubt in my mind it would have won if it wasn't for this error. ↩︎\n","wordCount":"777","inLanguage":"en","datePublished":"2019-08-19T00:00:00Z","dateModified":"2019-08-19T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://slerpy.xyz/posts/glitch-rider/"},"publisher":{"@type":"Organization","name":"This is slerpy","logo":{"@type":"ImageObject","url":"https://slerpy.xyz/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://slerpy.xyz/ accesskey=h title="This is slerpy (Alt + H)">This is slerpy</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://slerpy.xyz/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://slerpy.xyz/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://slerpy.xyz/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://slerpy.xyz/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://slerpy.xyz/legacy/ title=Legacy><span>Legacy</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://slerpy.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://slerpy.xyz/posts/>Posts</a></div><h1 class=post-title>Glitch Rider</h1><div class=post-meta><span title='2019-08-19 00:00:00 +0000 UTC'>August 19, 2019</span>&nbsp;·&nbsp;4 min</div></header><div class=post-content><p>a 4k PC intro released at Evoke 2019</p><p><img loading=lazy src=/glitch-rider/final.png alt=image></p><p>[<a href="https://www.pouet.net/prod.php?which=82612">pouët</a>]</p><p>This entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb.
It is the spiritual successor to <a href=/content/posts/kill-the-encoder/>Kill the Encoder</a>, which was my last 4k intro at the time.</p><h2 id=data-moshing>Data Moshing<a hidden class=anchor aria-hidden=true href=#data-moshing>#</a></h2><p>Many video codecs use inter-frame compression.
The idea is that a frame in a video typically looks similar to the frames immediately before and after it,
so most of the time, you can get away with storing only what changed between frames
rather than storing all the frames individually.
Roughly speaking, videos compressed this way are encoded as a sequence of I-frames and P-frames, where
An I-frame (intra-frame) specifies what an image looks like at the current point in time,
and a P-frame (predicted frame) only encodes changes between frames,
i.e. what transformations need to be applied to a different frame to obtain the current frame.</p><p>If an I-frame is corrupted or removed, the subsequent P-frames apply their transformations to the wrong base image.
If this happens while the video cuts from one shot to another,
you get the changes and camera movement from one shot but applied to another.
This is what we call data moshing.
There are plenty of tools that allow you to strategically remove I-frames from video files to create this effect yourself,
but of course, I couldn't use those in a 4k intro.</p><h2 id=how-to-fake-it>How to fake it<a hidden class=anchor aria-hidden=true href=#how-to-fake-it>#</a></h2><p>The intro takes a very different approach.
First, we do the usual camera ray intersection to find the surface point <code>p</code>.
Next, we check if <code>p</code> was on-screen on the previous frame,
first by checking if the point was occluded using another ray intersection,
then by computing the pixel coordinate where <code>p</code> should be visible and checking if it's within the bounds of the frame.
If we find <code>p</code> in the previous frame, we simply display its color, otherwise, we compute it from scratch.</p><p>This gives us a method to have textures "stick" to the geometry, similar to what TAA does.
Note that we only ever think about where the camera was in the last frame,
this method completely falls apart when the geometry moves,
which is why the scene is completely static in the intro.
In the shader, moving all the camera setup/movement into a separate <code>camera</code> function that takes the current time as a parameter makes this fairly easy to implement.</p><p>In its current state, if the camera jumps from one scene to another,
it detects that none of the points it sees were on-screen in the previous frame and discards all of them.
To get this data-moshing effect, we want to prevent it from detecting scene transitions like that.
So, to "remove the I-frame", we base all our jumps between scenes of the time of the current frame inside the <code>camera</code> function.
This way, we lie to the algorithm about where the camera was last frame, and that last frame sticks to the new geometry after the cut.</p><p>If you want to play around with that effect,
I made <a href=https://www.shadertoy.com/view/tlsSRs>Data Moshing Effect</a>,
a minimal Shadertoy that implements this algorithm.
Or rather, the intro is a fork of this Shadertoy.</p><h2 id=some-remarks>Some remarks<a hidden class=anchor aria-hidden=true href=#some-remarks>#</a></h2><p>You might notice that the Shadertoy uses one more buffer than necessary.
This is because every time the above algorithm is applied,
it introduces a small amount of error when fetching the texture.
So if you always fetch the previous frame,
you get an extremely unstable feedback loop where the image quickly starts to blur or deform.
To break this feedback loop, the shader only updates the "previous frame" texture every 8 frames.</p><p>Since posting the Shadertoy,
I have received multiple requests to rewrite the algorithm to work on arbitrary videos.
This is not feasible, as the algorithm relies on exact knowledge of the geometry in the scene
and precise 3D coordinates for every pixel on the screen.
If you want to data-mosh videos, messing with the video file directly is much easier.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This entry won first place in the 4k intro compo,
though arguably <a href="https://www.pouet.net/prod.php?which=82624">Eisenerz by LJ & Virgill</a> should have won <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.
When I first saw LJ's intro, I had doubts whether I should even submit mine.
I'm glad the other Alcatraz members talked me into it.</p><p>Also, thank you to xTr1m and Gopher for helping me debug this mess.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>As I found out later,
the live voting system stopped accepting votes almost immediately
after Eisenerz, the last intro in the compo, was shown,
meaning many votes for this intro were simply not counted.
There is no doubt in my mind it would have won if it wasn't for this error.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://slerpy.xyz/tags/demoscene/>demoscene</a></li><li><a href=https://slerpy.xyz/tags/4k/>4k</a></li><li><a href=https://slerpy.xyz/tags/intro/>intro</a></li></ul><nav class=paginav><a class=prev href=https://slerpy.xyz/posts/wackelkontakt/><span class=title>« Prev</span><br><span>Wackelkontakt</span></a>
<a class=next href=https://slerpy.xyz/posts/sler-py/><span class=title>Next »</span><br><span>sler.py</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://slerpy.xyz/>This is slerpy</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>