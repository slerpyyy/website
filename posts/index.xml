<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on This is slerpy</title><link>https://slerpy.xyz/posts/</link><description>Recent content in Posts on This is slerpy</description><image><title>This is slerpy</title><url>https://slerpy.xyz/papermod-cover.png</url><link>https://slerpy.xyz/papermod-cover.png</link></image><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 28 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://slerpy.xyz/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>New Website!</title><link>https://slerpy.xyz/posts/new-website/</link><pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/new-website/</guid><description>After not looking after my website for over 2 years, I finally decided to redo it entirely and turn the domain into a blog.
As I'm writing this, the new website is still kinda work in progress, so in case you want to visit the old one, there should be a &amp;quot;legacy&amp;quot; button in the top right corner1.
For the past couple of years, I've been making cool stuff and posting about it here and there, but I didn't have one place to document it all.</description></item><item><title>Generalizing Kaminski's Equation</title><link>https://slerpy.xyz/posts/generalizing-kaminskis-equation/</link><pubDate>Fri, 20 May 2022 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/generalizing-kaminskis-equation/</guid><description>The ideas in this write-up were originally explored in the context of the university course &amp;quot;Introduction to Computational Logic&amp;quot; by Prof. Gert Smolka and posted in the course-internal forum. Here, I want to elaborate on the forum post and give enough context to keep it mostly self-contained.
Kaminski's Equation In the lecture, we learned about Kaminski's equation, an interesting statement about functions on boolean values ($\mathbb{B}$). It formally states the following.</description></item><item><title>Cyclic Dripstone</title><link>https://slerpy.xyz/posts/cyclic-dripstone/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/cyclic-dripstone/</guid><description>2kb of GLSL shader code released at TokyoDemoFest 2021
[pouët]
In this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.
A typical path tracer with next event estimation You can think of a path tracer as being a system that computes how bright a given point in the scene is.</description></item><item><title>Kuwahara's Painting (桑原の絵画)</title><link>https://slerpy.xyz/posts/kuwaharas-painting/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/kuwaharas-painting/</guid><description>a 4k exe-gfx released at Tokyo Demo Fest 2021
[pouët]
Earlier in 2021, NuSan mentioned the Kuwahara filter in a discord server I'm in. The filter was originally invented to reduce noise in photos without making them look blurry, but it has the pleasant side effect of making images look a bit like paintings if the filter is applied with a sufficiently large kernel size.
I started by making a simple tree in a fragment shader.</description></item><item><title>Watchtower</title><link>https://slerpy.xyz/posts/watchtower/</link><pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/watchtower/</guid><description>a 4k exe-gfx released at Névoke 2021
[pouët]
This entry has been strongly inspired by the artist Windmill and especially their texture generator called JsPlacement.
Though, because of size limitations I was not able to embed a texture into the executable, so I made a very minimal copy of the tool using fragment shaders.
From here it was a matter of using the generated texture to create an interesting-looking scene. I used the texture as a heightmap for the floor, as a color map for the blue pattern over the geometry, and as displacement on the tower.</description></item><item><title>Off by One</title><link>https://slerpy.xyz/posts/off-by-one/</link><pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/off-by-one/</guid><description>a 4k exe-gfx released at Outline 2021
[pouët]
This entry started as a shower thought two days before the deadline: What if I wrote a path tracer but instead of starting the ray at the camera, I start tracing from the light source and put a point on the screen where the ray ends up?
This turned out to be fairly easy to implement in vertex shaders since they allow you to put points on the screen at given coordinates and also let you compute a lot of rays at once.</description></item><item><title>Würfelblitz</title><link>https://slerpy.xyz/posts/wuerfelblitz/</link><pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/wuerfelblitz/</guid><description>a 256b PC intro released at Revision 2021
[pouët]
This intro is a demonstration of a way to simulate buffer swaps using special color values, all within 256 bytes.
The naive way to render an effect like this would be to first clear the entire screen, then draw some lines and repeat. This works in theory but it creates a lot of flickering since you're very likely to see the image while it's in the middle of either clearing or rendering, meaning the lines are only partially visible.</description></item><item><title>Tesseract</title><link>https://slerpy.xyz/posts/tesseract/</link><pubDate>Sun, 04 Apr 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/tesseract/</guid><description>a 4k exe-gfx released at Revision 2021
[pouët]
I found yet another interesting way to render placeholder geometry :D
With this entry, I tried to recreate the look of a point cloud visualization, where there is one scanner in the middle of the scene that samples points outward and the camera is viewing the collected data from the outside.
To create a sense of depth, the points are colored according to how close to the scanner they are, and they are rendered with lots of depth of field.</description></item><item><title>Rise Again</title><link>https://slerpy.xyz/posts/rise-again/</link><pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/rise-again/</guid><description>my submission to the CG1 Rendering Competition at Saarland University
The rules of the competition required me to hand in a write-up with my submission, so here you go:
https://graphics.cg.uni-saarland.de/courses/cg1-2020/RC/Bies/
(In case the above link does not work, here is a backup link)
My entry ended up winning (joined) 1st place and they even gave me a prize after the final exam.</description></item><item><title>Convergence</title><link>https://slerpy.xyz/posts/convergence/</link><pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/convergence/</guid><description>a 4k exe-gfx entry released at NOVA 2020
[pouët]
This was my first proper exe-gfx entry. Up until this point, all of my entries have been real-time, meaning I always had to be careful with using system resources to ensure the entry runs at 60 fps in 1080p. So I decided I wanted to do something with tons of lines, rendered across multiple frames because I could.
The system I came up with initially would use one framebuffer to store the start and end position for millions of lines in the XY and ZW components of each pixel respectively, and a second shader would go through and render these onto the screen.</description></item><item><title>Every Color Once</title><link>https://slerpy.xyz/posts/every-color-once/</link><pubDate>Sun, 24 May 2020 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/every-color-once/</guid><description>This image contains every 18-bit color exactly once
I've been reminded of this age-old stack overflow coding challenge the other day and wanted to figure out how one could use fragment shaders to transform any input image into an image that uses every $n$-bit color exactly once.
The approach I took was to map every pixel from the input image into a ${(2^n)}^3$-cube, sort the pixels inside the cube by their RGB value respectively, and replace every pixel in the image by the final coordinate of the corresponding pixel inside the cube.</description></item><item><title>Wackelkontakt</title><link>https://slerpy.xyz/posts/wackelkontakt/</link><pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/wackelkontakt/</guid><description>a 4k PC intro released at Revision 2020
[pouët]
First of all, I want to thank noby for their amazing work with the intro. Not only are they responsible for the entire soundtrack and gave the visuals a final touch, but they also provided the 4k intro framework Leviathan-2.0, which this intro is based on.
As a disclaimer, this write-up will be written from my perspective, and I will hence not spend too much time talking about the music or how the framework as linked above works.</description></item><item><title>Glitch Rider</title><link>https://slerpy.xyz/posts/glitch-rider/</link><pubDate>Mon, 19 Aug 2019 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/glitch-rider/</guid><description>a 4k PC intro released at Evoke 2019
[pouët]
This entry is a demonstration of how to fake the data moshing effect using fragment shaders in 4kb. It is the spiritual successor to Kill the Encoder, which was my last 4k intro at the time.
Data Moshing Many video codecs use inter-frame compression. The idea is that a frame in a video typically looks similar to the frames immediately before and after it, so most of the time, you can get away with storing only what changed between frames rather than storing all the frames individually.</description></item><item><title>sler.py</title><link>https://slerpy.xyz/posts/sler-py/</link><pubDate>Sun, 18 Aug 2019 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/sler-py/</guid><description>The following exchange took place on March 18, 2019 in a conversation about domain hacks on discord:
slerpy I just realized if I do that with my handle, it looks a python script yx :D yx write a demo in python yx I want to see the beamslide for sler.py by slerpy
Yeah, so that's how that happened.
The Entry This is the 4k exe-gfx entry sler.py by slerpy, which renders a picture of slerpy.</description></item><item><title>Think Outside the Box</title><link>https://slerpy.xyz/posts/think-outside-the-box/</link><pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate><guid>https://slerpy.xyz/posts/think-outside-the-box/</guid><description>a 4k PC intro released at Under Construction 2018
[pouët]
In this intro, I wanted to play around with real-time graphics using baked, path-traced lighting. I am aware that baked lighting is quite popular in oldschool demos, but as far as I know, this is the first 4k PC intro to implement it.
The Lightmap The lighting information for all four rooms is stored in one flat texture, that is rendered at the start of the intro.</description></item></channel></rss>