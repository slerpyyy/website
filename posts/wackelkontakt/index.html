<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Wackelkontakt | This is slerpy</title><meta name=keywords content="demoscene,4k,intro"><meta name=description content="a 4k PC intro released at Revision 2020
[pouët]
First of all, I want to thank noby for their amazing work with the intro. Not only are they responsible for the entire soundtrack and gave the visuals a final touch, but they also provided the 4k intro framework Leviathan-2.0, which this intro is based on.
As a disclaimer, this write-up will be written from my perspective, and I will hence not spend too much time talking about the music or how the framework as linked above works."><meta name=author content><link rel=canonical href=https://slerpy.xyz/posts/wackelkontakt/><link crossorigin=anonymous href=/assets/css/stylesheet.7cea68b77c83e5da57c9a11c56919d4de2e6847751854f818c1d6aeb21f21f85.css integrity="sha256-fOpot3yD5dpXyaEcVpGdTeLmhHdRhU+BjB1q6yHyH4U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://slerpy.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://slerpy.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://slerpy.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://slerpy.xyz/apple-touch-icon.png><link rel=mask-icon href=https://slerpy.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Wackelkontakt"><meta property="og:description" content="a 4k PC intro released at Revision 2020
[pouët]
First of all, I want to thank noby for their amazing work with the intro. Not only are they responsible for the entire soundtrack and gave the visuals a final touch, but they also provided the 4k intro framework Leviathan-2.0, which this intro is based on.
As a disclaimer, this write-up will be written from my perspective, and I will hence not spend too much time talking about the music or how the framework as linked above works."><meta property="og:type" content="article"><meta property="og:url" content="https://slerpy.xyz/posts/wackelkontakt/"><meta property="og:image" content="https://slerpy.xyz/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-04-12T00:00:00+00:00"><meta property="article:modified_time" content="2020-04-12T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://slerpy.xyz/papermod-cover.png"><meta name=twitter:title content="Wackelkontakt"><meta name=twitter:description content="a 4k PC intro released at Revision 2020
[pouët]
First of all, I want to thank noby for their amazing work with the intro. Not only are they responsible for the entire soundtrack and gave the visuals a final touch, but they also provided the 4k intro framework Leviathan-2.0, which this intro is based on.
As a disclaimer, this write-up will be written from my perspective, and I will hence not spend too much time talking about the music or how the framework as linked above works."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://slerpy.xyz/posts/"},{"@type":"ListItem","position":2,"name":"Wackelkontakt","item":"https://slerpy.xyz/posts/wackelkontakt/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Wackelkontakt","name":"Wackelkontakt","description":"a 4k PC intro released at Revision 2020\n[pouët]\nFirst of all, I want to thank noby for their amazing work with the intro. Not only are they responsible for the entire soundtrack and gave the visuals a final touch, but they also provided the 4k intro framework Leviathan-2.0, which this intro is based on.\nAs a disclaimer, this write-up will be written from my perspective, and I will hence not spend too much time talking about the music or how the framework as linked above works.","keywords":["demoscene","4k","intro"],"articleBody":"a 4k PC intro released at Revision 2020\n[pouët]\nFirst of all, I want to thank noby for their amazing work with the intro. Not only are they responsible for the entire soundtrack and gave the visuals a final touch, but they also provided the 4k intro framework Leviathan-2.0, which this intro is based on.\nAs a disclaimer, this write-up will be written from my perspective, and I will hence not spend too much time talking about the music or how the framework as linked above works.\nInitial Experiments One day, I was thinking about sub-pixel rendering, a technique commonly used in text rendering to increase the apparent resolution of the image. It uses the fact that the red, green, and blue components of each pixel are at slightly different locations on the monitor to display graphics at a sub-pixel resolution.\nEven though this idea is nearly 50 years old, I haven't seen anyone use it on Shadertoy, so I wanted to try it. I made a little shader to render the Julia set fractal that computes 3x3 samples per pixel, where the left 3 samples contribute only to the red channel, the middle 3 control the green channel, and the right 3 the blue channel. To confirm the shader what working correctly, I took a couple of close-up photos of the screen with my phone.\nNow this looks cool and all, but unless you press your face against the monitor, you're probably not going to notice the difference. Maybe I should show the audience what the image looks like up close. So, I tried to recreate the above pictures using shaders alone. Here is an early WIP screenshot.\n(A slightly later version of this Shadertoy can be found here)\nThe Renderer The intro is rendered in 3 stages, the first stage renders the image displayed on the virtual monitor, the second simulates the camera hovering in front of the monitor using a simple ray tracer, and the third stage does some post-processing.\nThe first stage produces an image that matches exactly what is seen on the virtual monitor, meaning this stage already simulates sub-pixels. This works by applying a mask to the output of that stage pixels are colored in red, green, or blue according to their position. This is what that mask looks like.\nThis way, a 3x3 block of pixels corresponds to just one pixel on the monitor. Each of the effects shown on the screen may choose to use either the actual pixel position or the fake monitor pixel position to enable/disable sub-pixel rendering. From there, the effects are mostly just simple 2D effects.\nThe second stage simulates the camera in front of the monitor using a simple ray tracer, but this stage also takes care of anti-aliasing, depth of field, and a tiny bit of lighting.\nThe 'geometry' in this intro is just a single infinite plane at the origin. Since there is only one object and the camera never away from it, we can skip the intersection check entirely and go immediately from ray origin and direction (vec3 o, d) to the pixel coordinate we need to fetch to get the corresponding pixel on the screen.\nHere is the corresponding line from the intro:\nc+=texelFetch(D,ivec2(R.y*(o.xy-d.xy*o.z/d.z)+.5*R.xy),0) +.01*pow(.5+.5*d.y,3.); The part of the expression on the second line is some light coming from above that is being reflected off of the screen. This ended up being close to unnoticeable in the final intro, but I kept it in anyways.\nThis ended up being fast enough so we can render this with 200spp for DOF and AA. According to a Shadertoy comment, the shader runs smoothly even on blackle's phone.\nThe third stage only does a little bit of post-processing. Specifically, it does bloom, gamma correction, and finally adds some film grain.\nTo compute the bloom, we sample one of the low-res mipmap textures of the previous pass to save ourselves from blurring the image manually. This texture tends to be a bit blocky, so we sample it a couple of times in a circle around the current pixel.\nMiscellaneous Notes For the second and third 2D effect, I spent quite a lot of time going through different random seeds until I found a noise pattern I liked. The one I settled on for the third scene looks a little bit like there is the silhouette of a horse head in the center of the screen. (Maybe more like a chess figure, facing to the right? I don't blame you if you don't see it).\nWell it turns out the noise function we used is extremely platform dependent and it's fairly unlikely you get the same pattern when you run the intro locally. Here is the hashing function in question:\nvec2 H(vec2 p) { vec3 r=vec3(p,1); for (int i=0;i\u003c4;i++) r=fract(1e4*sin(r)+r.yzx); return r.xy; } The main source of randomness is the sin function, which is implemented slightly differently depending on what graphics card you're using, and this hash function is extremely good at amplifying these tiny differences. (If you want to experience the intro the way we intended, check out the video linked on the pouët page).\nAround the 1:32 timestamp, when the rain effect starts to distort, the lines slide sideways over the pixel grid, which causes the image to flicker violently. To prevent this, the saturation of the image is reduced to around 15% during the transition. This essentially disables the LCD-screen effect temporarily just to reduce flickering.\nOriginally, I also wanted to add chromatic aberration to the post-processing pass, but after some experiments, I realized this would strangely amplify the LCD-screen effect on the right side of the screen while almost completely canceling out the effect on the left, so I scrapped that idea. Here is a screenshot with chromab enabled.\nIn the last scene, there is a screen-space distortion effect applied in the first stage. This is done just to give the viewer something to focus on. Without it, we essentially get 2 layers of camera movement, both on and in front of the screen, which is quite disorienting to look at.\nConclusion This entry blew up way more than I expected. We won 3rd place in the compo, which is already insane considering Revision is the biggest pure demoparty in the world. A year later, we also won the Meteoriks award for Best High-end Intro and got nominated for Best Soundtrack and Best Visuals.\n","wordCount":"1070","inLanguage":"en","datePublished":"2020-04-12T00:00:00Z","dateModified":"2020-04-12T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://slerpy.xyz/posts/wackelkontakt/"},"publisher":{"@type":"Organization","name":"This is slerpy","logo":{"@type":"ImageObject","url":"https://slerpy.xyz/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://slerpy.xyz/ accesskey=h title="This is slerpy (Alt + H)">This is slerpy</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://slerpy.xyz/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://slerpy.xyz/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://slerpy.xyz/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://slerpy.xyz/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://slerpy.xyz/legacy/ title=Legacy><span>Legacy</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://slerpy.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://slerpy.xyz/posts/>Posts</a></div><h1 class=post-title>Wackelkontakt</h1><div class=post-meta><span title='2020-04-12 00:00:00 +0000 UTC'>April 12, 2020</span>&nbsp;·&nbsp;6 min</div></header><div class=post-content><p>a 4k PC intro released at Revision 2020</p><p><img loading=lazy src=/wackelkontakt/final.png alt=image></p><p>[<a href="https://www.pouet.net/prod.php?which=85220">pouët</a>]</p><p>First of all, I want to thank noby for their amazing work with the intro.
Not only are they responsible for the entire soundtrack and gave the visuals a final touch,
but they also provided the 4k intro framework <a href=https://github.com/armak/Leviathan-2.0>Leviathan-2.0</a>,
which this intro is based on.</p><p><strong>As a disclaimer</strong>, this write-up will be written from my perspective,
and I will hence not spend too much time talking about the music or how the framework as linked above works.</p><h2 id=initial-experiments>Initial Experiments<a hidden class=anchor aria-hidden=true href=#initial-experiments>#</a></h2><p>One day, I was thinking about <a href=https://en.wikipedia.org/wiki/subpixel_rendering>sub-pixel rendering</a>, a technique commonly used in text rendering to increase the apparent resolution of the image.
It uses the fact that the red, green, and blue components of each pixel are at slightly different locations on the monitor to display graphics at a sub-pixel resolution.</p><p>Even though this idea is nearly 50 years old, I haven't seen anyone use it on Shadertoy, so I wanted to try it.
I made a little shader to render the <a href=https://en.wikipedia.org/wiki/julia_set>Julia set fractal</a> that computes 3x3 samples per pixel, where the left 3 samples contribute only to the red channel, the middle 3 control the green channel, and the right 3 the blue channel.
To confirm the shader what working correctly, I took a couple of close-up photos of the screen with my phone.</p><p><img loading=lazy src=/wackelkontakt/photo-1.jpg alt=image>
<img loading=lazy src=/wackelkontakt/photo-2.jpg alt=image></p><p>Now this looks cool and all, but unless you press your face against the monitor, you're probably not going to notice the difference.
Maybe I should show the audience what the image looks like up close.
So, I tried to recreate the above pictures using shaders alone.
Here is an early WIP screenshot.</p><p><img loading=lazy src=/wackelkontakt/shader.jpg alt=image></p><p>(A slightly later version of this Shadertoy can be found <a href=https://www.shadertoy.com/view/lsfBzX>here</a>)</p><h2 id=the-renderer>The Renderer<a hidden class=anchor aria-hidden=true href=#the-renderer>#</a></h2><p>The intro is rendered in 3 stages,
the first stage renders the image displayed on the virtual monitor,
the second simulates the camera hovering in front of the monitor using a simple ray tracer,
and the third stage does some post-processing.</p><p><strong>The first stage</strong> produces an image that matches exactly what is seen on the virtual monitor, meaning this stage already simulates sub-pixels.
This works by applying a mask to the output of that stage pixels are colored in red, green, or blue according to their position.
This is what that mask looks like.</p><div align=center><img loading=lazy src=/wackelkontakt/mask.png alt=image></div><p>This way, a 3x3 block of pixels corresponds to just one pixel on the monitor.
Each of the effects shown on the screen may choose to use either the actual pixel position or the fake monitor pixel position to enable/disable sub-pixel rendering.
From there, the effects are mostly just simple 2D effects.</p><p><strong>The second stage</strong> simulates the camera in front of the monitor using a simple ray tracer,
but this stage also takes care of anti-aliasing, depth of field, and a tiny bit of lighting.</p><p>The 'geometry' in this intro is just a single infinite plane at the origin.
Since there is only one object and the camera never away from it,
we can skip the intersection check entirely and go immediately from ray origin and direction (<code>vec3 o, d</code>)
to the pixel coordinate we need to fetch to get the corresponding pixel on the screen.</p><p>Here is the corresponding line from the intro:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=display:flex><span>c<span style=color:#f92672>+=</span>texelFetch(D,<span style=color:#66d9ef>ivec2</span>(R.y<span style=color:#f92672>*</span>(o.xy<span style=color:#f92672>-</span>d.xy<span style=color:#f92672>*</span>o.z<span style=color:#f92672>/</span>d.z)<span style=color:#f92672>+</span><span style=color:#ae81ff>.5</span><span style=color:#f92672>*</span>R.xy),<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    <span style=color:#f92672>+</span><span style=color:#ae81ff>.01</span><span style=color:#f92672>*</span>pow(<span style=color:#ae81ff>.5</span><span style=color:#f92672>+</span><span style=color:#ae81ff>.5</span><span style=color:#f92672>*</span>d.y,<span style=color:#ae81ff>3.</span>);
</span></span></code></pre></div><p>The part of the expression on the second line is some light coming from above that is being reflected off of the screen.
This ended up being close to unnoticeable in the final intro, but I kept it in anyways.</p><p>This ended up being fast enough so we can render this with 200spp for DOF and AA.
According to a Shadertoy comment, the shader runs smoothly even on blackle's phone.</p><p><strong>The third stage</strong> only does a little bit of post-processing.
Specifically, it does bloom, gamma correction, and finally adds some film grain.</p><p>To compute the bloom, we sample one of the low-res mipmap textures of the previous pass to save ourselves from blurring the image manually.
This texture tends to be a bit blocky, so we sample it a couple of times in a circle around the current pixel.</p><h2 id=miscellaneous-notes>Miscellaneous Notes<a hidden class=anchor aria-hidden=true href=#miscellaneous-notes>#</a></h2><p>For the second and third 2D effect, I spent quite a lot of time going through different random seeds until I found a noise pattern I liked.
The one I settled on for the third scene looks a little bit like there is the silhouette of a horse head in the center of the screen.
(Maybe more like a chess figure, facing to the right? I don't blame you if you don't see it).</p><p><img loading=lazy src=/wackelkontakt/horse.png alt=image></p><p>Well it turns out the noise function we used is extremely platform dependent and it's fairly unlikely you get the same pattern when you run the intro locally.
Here is the hashing function in question:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-glsl data-lang=glsl><span style=display:flex><span><span style=color:#66d9ef>vec2</span> H(<span style=color:#66d9ef>vec2</span> p) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>vec3</span> r<span style=color:#f92672>=</span><span style=color:#66d9ef>vec3</span>(p,<span style=color:#ae81ff>1</span>);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>;i<span style=color:#f92672>&lt;</span><span style=color:#ae81ff>4</span>;i<span style=color:#f92672>++</span>)
</span></span><span style=display:flex><span>        r<span style=color:#f92672>=</span>fract(<span style=color:#ae81ff>1</span>e4<span style=color:#f92672>*</span>sin(r)<span style=color:#f92672>+</span>r.yzx);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> r.xy;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The main source of randomness is the <code>sin</code> function, which is implemented slightly differently depending on what graphics card you're using,
and this hash function is extremely good at amplifying these tiny differences.
(If you want to experience the intro the way we intended, check out the video linked on the pouët page).</p><p>Around the 1:32 timestamp, when the rain effect starts to distort,
the lines slide sideways over the pixel grid, which causes the image to flicker violently.
To prevent this, the saturation of the image is reduced to around 15% during the transition.
This essentially disables the LCD-screen effect temporarily just to reduce flickering.</p><p>Originally, I also wanted to add chromatic aberration to the post-processing pass,
but after some experiments, I realized this would strangely amplify the LCD-screen effect on the right side of the screen
while almost completely canceling out the effect on the left, so I scrapped that idea.
Here is a screenshot with chromab enabled.</p><p><img loading=lazy src=/wackelkontakt/chromab.png alt=image></p><p>In the last scene, there is a screen-space distortion effect applied in the first stage.
This is done just to give the viewer something to focus on.
Without it, we essentially get 2 layers of camera movement, both on and in front of the screen, which is quite disorienting to look at.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This entry blew up way more than I expected.
We won <strong>3rd place in the compo</strong>, which is already insane considering Revision is the biggest pure demoparty in the world.
A year later, we also won the <strong>Meteoriks award for Best High-end Intro</strong> and got nominated for <strong>Best Soundtrack</strong> and <strong>Best Visuals</strong>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://slerpy.xyz/tags/demoscene/>demoscene</a></li><li><a href=https://slerpy.xyz/tags/4k/>4k</a></li><li><a href=https://slerpy.xyz/tags/intro/>intro</a></li></ul><nav class=paginav><a class=prev href=https://slerpy.xyz/posts/every-color-once/><span class=title>« Prev</span><br><span>Every Color Once</span></a>
<a class=next href=https://slerpy.xyz/posts/glitch-rider/><span class=title>Next »</span><br><span>Glitch Rider</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://slerpy.xyz/>This is slerpy</a></span>
-
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>