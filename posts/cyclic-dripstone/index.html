<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cyclic Dripstone | This is slerpy</title><meta name=keywords content="demoscene,2k,shader"><meta name=description content="2kb of GLSL shader code released at TokyoDemoFest 2021
[pouët]
In this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.
A typical path tracer with next event estimation You can think of a path tracer as being a system that computes how bright a given point in the scene is."><meta name=author content><link rel=canonical href=https://slerpy.xyz/posts/cyclic-dripstone/><link crossorigin=anonymous href=/assets/css/stylesheet.7cea68b77c83e5da57c9a11c56919d4de2e6847751854f818c1d6aeb21f21f85.css integrity="sha256-fOpot3yD5dpXyaEcVpGdTeLmhHdRhU+BjB1q6yHyH4U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://slerpy.xyz/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://slerpy.xyz/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://slerpy.xyz/favicon-32x32.png><link rel=apple-touch-icon href=https://slerpy.xyz/apple-touch-icon.png><link rel=mask-icon href=https://slerpy.xyz/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Cyclic Dripstone"><meta property="og:description" content="2kb of GLSL shader code released at TokyoDemoFest 2021
[pouët]
In this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.
A typical path tracer with next event estimation You can think of a path tracer as being a system that computes how bright a given point in the scene is."><meta property="og:type" content="article"><meta property="og:url" content="https://slerpy.xyz/posts/cyclic-dripstone/"><meta property="og:image" content="https://slerpy.xyz/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-12T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-12T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://slerpy.xyz/papermod-cover.png"><meta name=twitter:title content="Cyclic Dripstone"><meta name=twitter:description content="2kb of GLSL shader code released at TokyoDemoFest 2021
[pouët]
In this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.
A typical path tracer with next event estimation You can think of a path tracer as being a system that computes how bright a given point in the scene is."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://slerpy.xyz/posts/"},{"@type":"ListItem","position":2,"name":"Cyclic Dripstone","item":"https://slerpy.xyz/posts/cyclic-dripstone/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Cyclic Dripstone","name":"Cyclic Dripstone","description":"2kb of GLSL shader code released at TokyoDemoFest 2021\n[pouët]\nIn this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.\nA typical path tracer with next event estimation You can think of a path tracer as being a system that computes how bright a given point in the scene is.","keywords":["demoscene","2k","shader"],"articleBody":"2kb of GLSL shader code released at TokyoDemoFest 2021\n[pouët]\nIn this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.\nA typical path tracer with next event estimation You can think of a path tracer as being a system that computes how bright a given point in the scene is. It starts by shooting a ray from the camera into the scene. At the intersection point, it needs to estimate how much light is emitted at that point, since that value directly affects how bright a specific pixel in the final image should be. We will consider a path tracer that has two estimators for this value, a BRDF sampling and NEE.\nIn BRDF (bidirectional reflectance distribution function) sampling, the renderer picks a random direction into which the incoming ray is likely to be reflected, intersects that ray with the scene and computes the brightness of the new intersection point recursively. This process typically repeats until a light source is hit or a maximum depth is reached.\nIn NEE (next event estimation), the renderer knows the position of every light source in the scene and uses it to sample the lights directly. This means from the intersection point, it picks a light source, checks if the light source is visible from the intersection point, and if so, returns the corresponding contribution.\nOnce both samples from the estimators are computed, they are combined using multiple importance sampling (MIS).\nWhat the shader does instead This entry uses similar ideas as described above, but the scene has been carefully designed to allow for large parts of the path tracer to be optimized away.\nThe scene has exactly one light source positioned at the origin, which makes NEE easy to implement with little code. Additionally, the dripstone cave around the sphere is (mostly) convex, meaning the light source is visible from every point on its surface, so the visibility check can be omitted. Finally, since the walls of the cave are relatively dark, the contribution we get from the BRDF estimator turns out to be so small that we can remove it entirely.\nNow that we have removed half the path tracer, this is what the renderer actually does:\nIntersect the camera ray with the scene (using sphere tracing) If we hit the sphere, return the emission texture for the intersection point. Otherwise, repeat the following 64 times: Pick a random point of the sphere facing the intersection point. Compute the emission at that point by looking up the emission texture. Weight the sample using the surface normal and wall color. Add the contribution to the accumulator. The result is an intro that looks like it's path traced, but in reality only computes one ray intersection per pixel per frame and runs smoothly in real-time.\nConclusion In retrospect, I kinda wish I made a 4k intro out of this, maybe something similar to Think Outside the Box, rather than releasing it as a shader without music, but this entry was very well received as-is. It ended up winning 2nd place in the compo and the organizers sent a trophy halfway around the world for my efforts.\n","wordCount":"548","inLanguage":"en","datePublished":"2021-12-12T00:00:00Z","dateModified":"2021-12-12T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://slerpy.xyz/posts/cyclic-dripstone/"},"publisher":{"@type":"Organization","name":"This is slerpy","logo":{"@type":"ImageObject","url":"https://slerpy.xyz/favicon.ico"}}}</script><style>#molivebuds{margin:0 auto;padding:15px;display:inline-block}#molivebuds table{background-color:var(--entry);margin:0 auto;border-radius:var(--radius)}#molivebuds table tr td{padding:15px}#molivebuds .webring-prev{text-align:right}#molivebuds .webring-info{text-align:center}#molivebuds .webring-next{text-align:left}#molivebuds .webring-links{font-size:small}</style></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://slerpy.xyz/ accesskey=h title="This is slerpy (Alt + H)">This is slerpy</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://slerpy.xyz/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://slerpy.xyz/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://slerpy.xyz/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://slerpy.xyz/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://slerpy.xyz/legacy/ title=Legacy><span>Legacy</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://slerpy.xyz/>Home</a>&nbsp;»&nbsp;<a href=https://slerpy.xyz/posts/>Posts</a></div><h1 class=post-title>Cyclic Dripstone</h1><div class=post-meta><span title='2021-12-12 00:00:00 +0000 UTC'>December 12, 2021</span>&nbsp;·&nbsp;3 min</div></header><div class=post-content><p>2kb of GLSL shader code released at TokyoDemoFest 2021</p><p><img loading=lazy src=/cyclic-dripstone/final.png alt=image></p><p>[<a href="https://www.pouet.net/prod.php?which=90426">pouët</a>]</p><p>In this entry demonstrates a way to approximate the lighting you get from a path tracer in a way that's fast enough to run in real-time while still using SDF ray marching to render the scene.</p><h2 id=a-typical-path-tracer-with-next-event-estimation>A typical path tracer with next event estimation<a hidden class=anchor aria-hidden=true href=#a-typical-path-tracer-with-next-event-estimation>#</a></h2><p>You can think of a path tracer as being a system that computes how bright a given point in the scene is.
It starts by shooting a ray from the camera into the scene.
At the intersection point, it needs to estimate how much light is emitted at that point, since that value directly affects how bright a specific pixel in the final image should be.
We will consider a path tracer that has two estimators for this value, a BRDF sampling and NEE.</p><ul><li><p>In BRDF (bidirectional reflectance distribution function) sampling, the renderer picks a random direction into which the incoming ray is likely to be reflected, intersects that ray with the scene and computes the brightness of the new intersection point recursively. This process typically repeats until a light source is hit or a maximum depth is reached.</p></li><li><p>In NEE (next event estimation), the renderer knows the position of every light source in the scene and uses it to sample the lights directly. This means from the intersection point, it picks a light source, checks if the light source is visible from the intersection point, and if so, returns the corresponding contribution.</p></li></ul><p>Once both samples from the estimators are computed, they are combined using multiple importance sampling (MIS).</p><h2 id=what-the-shader-does-instead>What the shader does instead<a hidden class=anchor aria-hidden=true href=#what-the-shader-does-instead>#</a></h2><p>This entry uses similar ideas as described above, but the scene has been carefully designed to allow for large parts of the path tracer to be optimized away.</p><p>The scene has exactly one light source positioned at the origin, which makes NEE easy to implement with little code.
Additionally, the dripstone cave around the sphere is (mostly) convex, meaning the light source is visible from every point on its surface, so the visibility check can be omitted.
Finally, since the walls of the cave are relatively dark, the contribution we get from the BRDF estimator turns out to be so small that we can remove it entirely.</p><p>Now that we have removed half the path tracer, this is what the renderer actually does:</p><ul><li>Intersect the camera ray with the scene (using sphere tracing)</li><li>If we hit the sphere, return the emission texture for the intersection point.</li><li>Otherwise, repeat the following 64 times:<ul><li>Pick a random point of the sphere facing the intersection point.</li><li>Compute the emission at that point by looking up the emission texture.</li><li>Weight the sample using the surface normal and wall color.</li><li>Add the contribution to the accumulator.</li></ul></li></ul><p>The result is an intro that looks like it's path traced, but in reality only computes one ray intersection per pixel per frame and runs smoothly in real-time.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>In retrospect, I kinda wish I made a 4k intro out of this,
maybe something similar to <a href=/posts/think-outside-the-box/>Think Outside the Box</a>,
rather than releasing it as a shader without music,
but this entry was very well received as-is.
It ended up winning 2nd place in the compo and the organizers sent a trophy halfway around the world for my efforts.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://slerpy.xyz/tags/demoscene/>demoscene</a></li><li><a href=https://slerpy.xyz/tags/2k/>2k</a></li><li><a href=https://slerpy.xyz/tags/shader/>shader</a></li></ul><nav class=paginav><a class=prev href=https://slerpy.xyz/posts/generalizing-kaminskis-equation/><span class=title>« Prev</span><br><span>Generalizing Kaminski's Equation</span></a>
<a class=next href=https://slerpy.xyz/posts/kuwaharas-painting/><span class=title>Next »</span><br><span>Kuwahara's Painting (桑原の絵画)</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://slerpy.xyz/>This is slerpy</a></span>
-
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>